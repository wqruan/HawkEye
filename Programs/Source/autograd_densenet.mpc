import nn as nn
from tensor import Tensor,autograd_function
import optimizer as optim
import dataloader as dataloader
import functional as F
program.use_trunc_pr = True
sfix.set_precision(23, 59)
cfix.set_precision(23, 59)
class FirstConv(nn.Module):
    def __init__(self, channels_in, channels_out):
        """
        DenseNet，3
        :param channels_in: 
        :param channels_out: 
        """
        super().__init__()
        self.layers = nn.Sequential(nn.Conv2d(in_channels=channels_in, out_channels=channels_out, kernel_size=3, stride=2, padding=3, bias=False),
                                    nn.BatchNorm2d(num_features=channels_out),
                                    nn.ReLU(),
                                    nn.AvgPool2d(kernel_size=2))
    def forward(self, x):
        return self.layers(x)

class BottleneckLayer(nn.Module):
    def __init__(self, channels_in, growth_rate):
        super().__init__()
        self.growth_rate = growth_rate
        self.channels_in = channels_in
        self.out_channels_1x1 = 4*self.growth_rate
        self.layers = nn.Sequential(nn.BatchNorm2d(num_features=self.channels_in),
                                    nn.ReLU(),
                                    nn.Conv2d(in_channels=self.channels_in, out_channels=self.out_channels_1x1, kernel_size=1, padding=0,bias=False),
                                    nn.BatchNorm2d(num_features=self.out_channels_1x1),
                                    nn.ReLU(),
                                    nn.Conv2d(in_channels=self.out_channels_1x1, out_channels=self.growth_rate, kernel_size=3, stride=1, padding=1, bias=False))

    def forward(self, x):
        out = self.layers(x)
        # ：x
        out = x.concat(out, dim=1)
        return out

class TransitionLayer(nn.Module):
    def __init__(self, channels_in, channels_out):
        super().__init__()
        # 1：
        self.channels_in = channels_in
        self.channels_out = channels_out
        # 2：BN+ReLU+Conv1x1+AvgPool2x2
        self.layers = nn.Sequential(nn.BatchNorm2d(num_features=channels_in),
                                    nn.ReLU(),
                                    nn.Conv2d(in_channels=channels_in, out_channels=channels_out, kernel_size=1, stride=1, padding=0, bias=False),
                                    nn.AvgPool2d(kernel_size=2))

    def forward(self, x):
        out = self.layers(x)
        return out

def make_dense_block(num_bottleneck, growth_rate, channels_in):
    """
    BottleneckDense Block
    :param num_bottleneck: Dense Block
    :param growth_rate: ，
    :param channels_in: 
    :return: nn.SequentialDense Block
    """
    # 1：
    layers = []
    # 2：bottleneckbottleneck
    #    bottleneckk，growth rate
    current_channels = channels_in
    for i in range(num_bottleneck):
        # 3：Dense BlockBottleneck
        layers.append(BottleneckLayer(channels_in=current_channels, growth_rate=growth_rate))
        # 4：current_channelsgrowth rate
        current_channels += growth_rate
    return nn.Sequential(*layers)

class DenseNet(nn.Module):
    def __init__(self, growth_rate, channels_in, num_dense_block, num_bottleneck, num_channels_before_dense, compression, num_classes):
        """
        DenseNet
        :param growth_rate: 
        :param channels_in: 
        :param num_dense_block: Dense Block，
        :param num_bottleneck: listDenseBlockbottleneck，list(6, 12, 24, 16)DenseNet121
        :param num_channels_before_dense: 
        :param compression: ，TransitionCompression
        :param num_classes:
        """
        super().__init__()
        self.growth_rate = growth_rate
        self.channel_in = channels_in
        self.num_dense_block = num_dense_block
        self.num_bottleneck = num_bottleneck

        # 1：1
        self.first_conv = FirstConv(channels_in=channels_in, channels_out=num_channels_before_dense)

        # 2：1Dense Block，*
        self.dense_1 = make_dense_block(num_bottleneck=num_bottleneck[0], channels_in=num_channels_before_dense,
                                        growth_rate=growth_rate)
        dense_1_out_channels = int(num_channels_before_dense + num_bottleneck[0]*growth_rate)
        self.transition_1 = TransitionLayer(channels_in=dense_1_out_channels,
                                            channels_out=int(compression*dense_1_out_channels))

        # 3：2Dense Block，*
        self.dense_2 = make_dense_block(num_bottleneck=num_bottleneck[1], channels_in=int(compression*dense_1_out_channels),
                                        growth_rate=growth_rate)
        dense_2_out_channels = int(compression*dense_1_out_channels + num_bottleneck[1]*growth_rate)
        self.transition_2 = TransitionLayer(channels_in=dense_2_out_channels,
                                            channels_out=int(compression*dense_2_out_channels))

        # 4：3Dense Block，*
        self.dense_3 = make_dense_block(num_bottleneck=num_bottleneck[2], channels_in=int(compression * dense_2_out_channels),
                                        growth_rate=growth_rate)
        dense_3_out_channels = int(compression * dense_2_out_channels + num_bottleneck[2] * growth_rate)
        self.transition_3 = TransitionLayer(channels_in=dense_3_out_channels,
                                            channels_out=int(compression * dense_3_out_channels))

        # 5：4Dense Block， * 
        self.dense_4 = make_dense_block(num_bottleneck=num_bottleneck[3],
                                        channels_in=int(compression * dense_3_out_channels),
                                        growth_rate=growth_rate)
        dense_4_out_channels = int(compression * dense_3_out_channels + num_bottleneck[3] * growth_rate)

        # 6：7x7，
        self.BN_before_classify = nn.BatchNorm2d(num_features=dense_4_out_channels)
        self.pool_before_classify = nn.AvgPool2d(kernel_size=7)
        self.classify = nn.Linear(in_features=dense_4_out_channels, out_features=num_classes)


    def forward(self, x):
        out_1 = self.first_conv(x)
        out_2 = self.transition_1(self.dense_1(out_1))
        out_3 = self.transition_2(self.dense_2(out_2))
        out_4 = self.transition_3(self.dense_3(out_3))
        out_5 = self.dense_4(out_4)
        out_6 = self.BN_before_classify(out_5)
        out_7 = self.pool_before_classify(out_6)
        out_8 = self.classify(out_7.view(x.size(0), -1))
        return out_8

model = DenseNet(channels_in=3, compression=0.5, growth_rate=32, num_classes=1000,num_bottleneck=[6, 12, 24, 16],
                       num_channels_before_dense=64,
                       num_dense_block=4)
# model = DenseNet(channels_in=3, compression=0.5, growth_rate=32, num_classes=10,num_bottleneck=[2,4, 8,4],
#                         num_channels_before_dense=64,
#                         num_dense_block=4)
x = Tensor.ones(4, 3, 224, 224)
labels = Tensor.ones(4, 1000)
crossloss = nn.CrossEntropyLoss()
dataload = dataloader.DataLoader(x, labels, batch_size = 1, shuffle=False)
optimizer = optim.SGD(model.parameters(), lr = 0.01)
input, label = dataload.get_data(0)
# model.train(crossloss, dataload)

output = model(input)
#loss = crossloss(output, label)
#optimizer.zero_grad()
#loss.backward()
#output.print_reveal_nested()


