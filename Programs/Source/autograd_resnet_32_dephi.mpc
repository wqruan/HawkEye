import nn as nn
from tensor import Tensor,autograd_function
import optimizer as optim
import dataloader as dataloader
import functional as F
program.use_trunc_pr = True
sfix.set_precision(18, 59)
cfix.set_precision(18, 59)

class BasicBlock(nn.Module):
    extention = 1

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=1, padding=1, bias=False)

        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)


        # if stride != 1 or in_planes != self.extention*planes:
        #     self.shortcut = nn.Sequential(
        #         nn.Conv2d(in_planes, self.extention*planes, kernel_size=1, stride=stride, bias=False),
        #         nn.Identity()
        #     )

    def forward(self, x):

        out = F.relu(self.conv1(x))
        out = self.conv2(out)
        # out += self.shortcut(x)
        out = F.relu(out)
        return out
    
class ResBlock(nn.Module):
    def __init__(self, in_planes, planes, size):
        super(ResBlock, self).__init__()
        # self.conv1 = ./


        self.shortcut = nn.Identity()
        # if stride != 1 or in_planes != self.extention*planes:
        #     self.shortcut = nn.Sequential(
        #         nn.Conv2d(in_planes, self.extention*planes, kernel_size=1, stride=stride, bias=False),
        #         nn.Identity()
        #     )
        self.blocks =[]
        for i in range(size):
            self.blocks.append(BasicBlock(planes, planes,1))
    def forward(self, x):
        # x = self.conv1(x)
        for block in self.blocks:
            x= block(x)
        return x

class ResNet(nn.Module):
    def __init__(self,block,layers,num_class):
        #inplane=fm
        self.inplane=16
        super(ResNet, self).__init__()

        #
        self.block=block
        self.layers=layers

        #stem
        self.conv1=nn.Conv2d(3,self.inplane,kernel_size=3,stride=1,padding=1,bias=False)
        # self.bn1=nn.Identity()
        self.relu=nn.ReLU()
        # self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)

        self.tmp1 = nn.Conv2d(self.inplane, 16, kernel_size=3, stride=1, padding=1, bias=False)
        #64,128,256,5124，Identity Block
        self.stage1=self.make_layer(self.block,16,layers[0],stride=1)
        self.tmp2 = nn.Conv2d(self.inplane, 32, kernel_size=3, stride=2, padding=1, bias=False)
        self.stage2=self.make_layer(self.block,32,layers[1],stride=2)
        self.tmp3 = nn.Conv2d(self.inplane, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.stage3=self.make_layer(self.block,64,layers[2],stride=2)
        # self.stage4=self.make_layer(self.block,512,layers[3],stride=2)

        #
        self.avgpool=nn.AvgPool2d(kernel_size =2 ,stride= 2)
        self.fc=nn.Linear(64*16,num_class)

    def forward(self,x):
        #stem：conv+bn+maxpool
        out=self.conv1(x)
        # out=self.bn1(out)
        out=self.relu(out)


        #block
        out = self.tmp1(out)
        out=self.stage1(out)
        out = self.tmp2(out)
        out=self.stage2(out)
        out = self.tmp3(out)
        
        out=self.stage3(out)
        # out=self.stage4(out)

        #
        out=self.avgpool(out)
        print(out.sizes)
        out=out.flatten(1,-1)
        out=self.fc(out)

        return out

    def make_layer(self,block,plane,block_num,stride=1):
        '''
        :param block: block
        :param plane: ，/4
        :param block_num: 
        :param stride: 
        :return:
        '''
        # res = ResBlock(self.inplane, plane, 5)
        blocks =[]
        for i in range(5):
            blocks.append(BasicBlock(plane, plane,1))
        self.inplane = plane
        return nn.Sequential(*blocks)

model=ResNet(BasicBlock,[5, 5, 5],10)
x = Tensor.ones(4, 3, 32, 32)
labels = Tensor.ones(4, 32)
crossloss = nn.CrossEntropyLoss()
dataload = dataloader.DataLoader(x, labels, batch_size = 1, shuffle=False)
optimizer = optim.SGD(model.parameters(), lr = 0.01)
input, label = dataload.get_data(0)

output = model(input)
